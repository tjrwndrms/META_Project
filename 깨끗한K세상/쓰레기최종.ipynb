{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "from PIL import Image, ImageFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 결정\n",
    "seed_num = 11\n",
    "np.random.seed(seed_num)\n",
    "torch.manual_seed(seed_num)\n",
    "\n",
    "# 폴더에서 데이터 로드\n",
    "train_dir = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\쓰레기\\\\Training\"\n",
    "val_dir = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\쓰레기\\\\Validation\"\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir)\n",
    "val_dataset = ImageFolder(root=val_dir)\n",
    "\n",
    "# PIL에서 손상된 이미지 처리\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# 커스텀 데이터셋 클래스 정의\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            return super(CustomImageFolder, self).__getitem__(index)\n",
    "        except OSError as e:\n",
    "            print(f\"Error loading image at index {index}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더에서 데이터 로드\n",
    "train_dataset = CustomImageFolder(root=\"C:\\\\Users\\\\Admin\\\\Desktop\\\\쓰레기\\\\Training\")\n",
    "val_dataset = CustomImageFolder(root=\"C:\\\\Users\\\\Admin\\\\Desktop\\\\쓰레기\\\\Validation\")\n",
    "\n",
    "# 전체 데이터 사용\n",
    "train_indices = list(range(len(train_dataset)))\n",
    "val_indices = list(range(len(val_dataset)))\n",
    "\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(val_dataset, val_indices)\n",
    "\n",
    "# 데이터 로더 설정에 collate_fn 추가\n",
    "def custom_collate_fn(batch):\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 변환 설정\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# transform 설정\n",
    "train_subset.dataset.transform = train_transform\n",
    "val_subset.dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더 설정\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# 사전 훈련된 모델 가져오기 및 수정\n",
    "transfer_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# 모든 레이어를 고정\n",
    "for param in transfer_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 마지막 레이어 교체\n",
    "num_ftrs = transfer_model.fc.in_features\n",
    "transfer_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(1024, len(train_dataset.classes))  # 클래스 수에 맞게 변경\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transfer_model = transfer_model.to(device)\n",
    "\n",
    "# 손실 함수 및 최적화 알고리즘 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(transfer_model.fc.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 함수\n",
    "def train_and_validate_best(model, train_loader, val_loader, optimizer, criterion, epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    min_val_loss = float('inf')  # 가장 좋은 모델을 추적하기 위한 변수 초기화\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # 검증 과정\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        accuracy_metric = torchmetrics.Accuracy(task='multiclass', num_classes=len(train_dataset.classes), average='macro').to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "                accuracy_metric.update(outputs, labels)\n",
    "            accuracy = accuracy_metric.compute()  # 정확도 계산\n",
    "            accuracies.append(accuracy.item())\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}] - Training loss: {epoch_loss:.3f}, Validation loss: {epoch_val_loss:.3f}, accuracy: {accuracy:.2%}')\n",
    "\n",
    "        # 가장 좋은 모델만 저장\n",
    "        if epoch_val_loss < min_val_loss:\n",
    "            min_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Best model saved at epoch {epoch + 1}.')\n",
    "\n",
    "    return train_losses, val_losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19061 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = train_and_validate_best(transfer_model, train_loader, val_loader, optimizer, criterion, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 불러오기\n",
    "transfer_model_best = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = transfer_model_best.fc.in_features\n",
    "transfer_model_best.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(1024, len(train_dataset.classes))\n",
    ")\n",
    "transfer_model_best.load_state_dict(torch.load('best_model.pth'))\n",
    "transfer_model_best = transfer_model_best.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 및 검증 손실 시각화\n",
    "train_losses, val_losses, accuracies = history\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, 'bo-', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'ro-', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 함수\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    accuracy_metric = torchmetrics.Accuracy(task='multiclass', num_classes=len(train_dataset.classes), average='macro').to(device)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "    accuracy = accuracy_metric.compute()\n",
    "    return accuracy.item()\n",
    "\n",
    "# 최종 모델 평가\n",
    "test_accuracy = evaluate(transfer_model_best, val_loader, device)\n",
    "print(f'Test Accuracy: {test_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 목록 출력\n",
    "class_names = train_dataset.classes\n",
    "print(\"Model classes:\")\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    print(f\"{idx}: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가에 사용할 이미지 로드 및 변환 함수\n",
    "def load_img(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = test_transform(image).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "# 예측 함수\n",
    "def predict_image(model, image_path, class_names):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            input_image = load_img(image_path).to(device)\n",
    "            outputs = model(input_image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            original_img = input_image.squeeze(0).cpu().detach().numpy().transpose((1, 2, 0))\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            original_img = std * original_img + mean\n",
    "            original_img = np.clip(original_img, 0, 1)\n",
    "\n",
    "            plt.imshow(original_img)\n",
    "            plt.title(f'Predicted: {class_names[preds.item()]}')\n",
    "            plt.show()\n",
    "            print(\"모델 예측 결과 :\", preds)\n",
    "            print(\"모델 예측 결과 :\", class_names[preds.item()])\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing image: {e}\")\n",
    "\n",
    "# 평가할 이미지 파일 경로 설정\n",
    "image_path1 = \"C:\\\\Project\\\\Python_basic\\\\깨끗한K세상\\\\test\\\\페트병 쓰레기.jpg\"\n",
    "image_path2 = \"C:\\\\Project\\\\Python_basic\\\\깨끗한K세상\\\\test\\\\캔 쓰레기.jpg\"\n",
    "\n",
    "# 파일 존재 여부 확인 및 예측 수행\n",
    "for image_path in [image_path1, image_path2]:\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: The file {image_path} does not exist.\")\n",
    "        print(f\"Current working directory: {os.getcwd()}\")\n",
    "        print(f\"Provided path: {image_path}\")\n",
    "    else:\n",
    "        predict_image(transfer_model_best, image_path, train_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모르겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 랜덤 시드 결정\n",
    "seed_num = 11\n",
    "np.random.seed(seed_num)\n",
    "torch.manual_seed(seed_num)\n",
    "\n",
    "# 폴더에서 데이터 로드\n",
    "train_dir = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\쓰레기\\\\Training\"\n",
    "val_dir = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\쓰레기\\\\Validation\"\n",
    "\n",
    "train_dataset = ImageFolder(root=train_dir)\n",
    "val_dataset = ImageFolder(root=val_dir)\n",
    "\n",
    "# 각 클래스당 10% 데이터 샘플링\n",
    "def get_subset_indices(dataset, percentage=0.1):\n",
    "    indices = []\n",
    "    targets_np = np.array(dataset.targets)\n",
    "    for class_idx in range(len(dataset.classes)):\n",
    "        class_indices = np.where(targets_np == class_idx)[0]\n",
    "        selected_indices = np.random.choice(class_indices, int(len(class_indices) * percentage), replace=False)\n",
    "        indices.extend(selected_indices)\n",
    "    return indices\n",
    "\n",
    "train_indices = get_subset_indices(train_dataset, percentage=0.1)\n",
    "val_indices = get_subset_indices(val_dataset, percentage=0.1)\n",
    "\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(val_dataset, val_indices)\n",
    "\n",
    "# 데이터 변환 설정\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# transform 설정\n",
    "train_subset.dataset.transform = train_transform\n",
    "val_subset.dataset.transform = test_transform\n",
    "\n",
    "# 데이터 로더 설정\n",
    "batch_size = 4\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 사전 훈련된 모델 가져오기 및 수정\n",
    "transfer_model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# 마지막 몇 개의 레이어만 고정하지 않음\n",
    "for name, param in transfer_model.named_parameters():\n",
    "    if 'layer4' in name or 'fc' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# 마지막 레이어 교체\n",
    "num_ftrs = transfer_model.fc.in_features\n",
    "transfer_model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, len(train_dataset.classes))  # 클래스 수에 맞게 변경\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transfer_model = transfer_model.to(device)\n",
    "\n",
    "# 손실 함수 및 최적화 알고리즘 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(transfer_model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# 학습률 스케줄러 설정\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "# 모델 학습 함수\n",
    "def train_and_validate_best(model, train_loader, val_loader, optimizer, criterion, scheduler, epochs, patience):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    min_val_loss = float('inf')  # 가장 좋은 모델을 추적하기 위한 변수 초기화\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        # 검증 과정\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        accuracy_metric = torchmetrics.Accuracy(task='multiclass', num_classes=len(train_dataset.classes), average='macro').to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "                accuracy_metric.update(outputs, labels)\n",
    "            accuracy = accuracy_metric.compute()  # 정확도 계산\n",
    "            accuracies.append(accuracy.item())\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}] - Training loss: {epoch_loss:.3f}, Validation loss: {epoch_val_loss:.3f}, accuracy: {accuracy:.2%}')\n",
    "\n",
    "        # 가장 좋은 모델만 저장\n",
    "        if epoch_val_loss < min_val_loss:\n",
    "            min_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Best model saved at epoch {epoch + 1}.')\n",
    "            early_stop_counter = 0  # 초기화\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f'Early stopping at epoch {epoch + 1}')\n",
    "                break\n",
    "\n",
    "        # 학습률 스케줄러 업데이트\n",
    "        scheduler.step(epoch_val_loss)\n",
    "\n",
    "    return train_losses, val_losses, accuracies\n",
    "\n",
    "# 모델 학습\n",
    "history = train_and_validate_best(transfer_model, train_loader, val_loader, optimizer, criterion, scheduler, epochs=100, patience=10)\n",
    "\n",
    "# 학습된 모델 불러오기\n",
    "transfer_model_best = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = transfer_model_best.fc.in_features\n",
    "transfer_model_best.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, len(train_dataset.classes))\n",
    ")\n",
    "transfer_model_best.load_state_dict(torch.load('best_model.pth'))\n",
    "transfer_model_best = transfer_model_best.to(device)\n",
    "\n",
    "# 학습 및 검증 손실 시각화\n",
    "train_losses, val_losses, accuracies = history\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, 'bo-', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'ro-', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델 평가 함수\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    accuracy_metric = torchmetrics.Accuracy(task='multiclass', num_classes=len(train_dataset.classes), average='macro').to(device)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "    accuracy = accuracy_metric.compute()\n",
    "    return accuracy.item()\n",
    "\n",
    "# 최종 모델 평가\n",
    "test_accuracy = evaluate(transfer_model_best, val_loader, device)\n",
    "print(f'Test Accuracy: {test_accuracy:.2%}')\n",
    "\n",
    "# 클래스 목록 출력\n",
    "class_names = train_dataset.classes\n",
    "print(\"Model classes:\")\n",
    "for idx, class_name in enumerate(class_names):\n",
    "    print(f\"{idx}: {class_name}\")\n",
    "\n",
    "# 평가에 사용할 이미지 로드 및 변환 함수\n",
    "def load_img(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = test_transform(image).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "# 예측 함수\n",
    "def predict_image(model, image_path, class_names):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            input_image = load_img(image_path).to(device)\n",
    "            outputs = model(input_image)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            original_img = input_image.squeeze(0).cpu().detach().numpy().transpose((1, 2, 0))\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            original_img = std * original_img + mean\n",
    "            original_img = np.clip(original_img, 0, 1)\n",
    "\n",
    "            plt.imshow(original_img)\n",
    "            plt.title(f'Predicted: {class_names[preds.item()]}')\n",
    "            plt.show()\n",
    "            print(\"모델 예측 결과 :\", preds)\n",
    "            print(\"모델 예측 결과 :\", class_names[preds.item()])\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing image: {e}\")\n",
    "\n",
    "# 평가할 이미지 파일 경로 설정\n",
    "image_path1 = \"C:\\\\Project\\\\Python_basic\\\\깨끗한K세상\\\\test\\\\페트병 쓰레기.jpg\"\n",
    "image_path2 = \"C:\\\\Project\\\\Python_basic\\\\깨끗한K세상\\\\test\\\\캔 쓰레기.jpg\"\n",
    "\n",
    "# 파일 존재 여부 확인 및 예측 수행\n",
    "for image_path in [image_path1, image_path2]:\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: The file {image_path} does not exist.\")\n",
    "        print(f\"Current working directory: {os.getcwd()}\")\n",
    "        print(f\"Provided path: {image_path}\")\n",
    "    else:\n",
    "        predict_image(transfer_model_best, image_path, train_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gumi_env310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
