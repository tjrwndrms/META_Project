{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MP4 파일을 MP3로 파일 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "\n",
    "video = VideoFileClip('./test_video.mp4')\n",
    "\n",
    "video.audio.write_audiofile('./test_video.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 텍스트 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens = 128,\n",
    "    chunk_length_s = 30,\n",
    "    batch_size = 16,\n",
    "    return_timestamps = True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "speech_output_path = './test_video.mp3'\n",
    "result_openai = pipe(speech_output_path)\n",
    "\n",
    "with open('stt_file.txt', 'w', encoding='utf-8') as stt_file:\n",
    "    stt_file.write(result_openai[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 이전 내용 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] =\"\"\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('./stt_file.txt', encoding='utf-8')\n",
    "document = loader.load()\n",
    "\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=3000, chunk_overlap=300)\n",
    "\n",
    "def summarize_review(review):\n",
    "    docs = text_splitter.create_documents([review])\n",
    "\n",
    "    map_prompt_template = '''다음 복숭아 제품을 판매하는 홈쇼핑 대본을 참고하여 제품의 장단점을 bullet으로 요약해줘\n",
    "    대본 : {text}\n",
    "    '''\n",
    "    combine_prompt_template = '''다음 bullet summary를 종합하여 홈쇼핑 제품의 특징을 요약해줘:{text}\n",
    "    '''\n",
    "    \n",
    "    MAP_PROMPT = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "    COMBINE_PROMPT = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
    "    \n",
    "    chain = load_summarize_chain(ChatOpenAI(temperature=0, model_name = 'gpt-4o-mini'),\n",
    "                                  chain_type=\"map_reduce\", return_intermediate_steps=True,\n",
    "                                  map_prompt=MAP_PROMPT, combine_prompt=COMBINE_PROMPT)\n",
    "    \n",
    "    return chain({\"input_documents\": docs}, return_only_outputs=True)\n",
    "\n",
    "summarize_review(document[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from moviepy.editor import *\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "chat_model = ChatOpenAI(temperature=0, model_name = 'gpt-4o-mini')\n",
    "\n",
    "def video2voice(video_path):\n",
    "    video = VideoFileClip(video_path)\n",
    "    video.audio.write_audiofile('./voice/test_video.mp3')\n",
    "    \n",
    "def voice2text(voice_path):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "    model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    pipe = pipeline(\n",
    "        \"automatic-speech-recognition\",\n",
    "        model=model,\n",
    "        tokenizer=processor.tokenizer,\n",
    "        feature_extractor=processor.feature_extractor,\n",
    "        max_new_tokens = 128,\n",
    "        chunk_length_s = 30,\n",
    "        batch_size = 16,\n",
    "        return_timestamps = True,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    result_openai = pipe(voice_path)\n",
    "    \n",
    "    with open('./text/stt_file.txt', 'w', encoding='utf-8') as stt_file:\n",
    "        stt_file.write(result_openai[\"text\"])\n",
    "\n",
    "def before_streaming_summarize(chat_model, text_path):\n",
    "    \n",
    "    loader = TextLoader(text_path, encoding='utf-8')\n",
    "    document = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=3000, chunk_overlap=300)\n",
    "    \n",
    "    docs = text_splitter.create_documents([document[0].page_content])\n",
    "\n",
    "    map_prompt_template = '''\n",
    "        너는 라이브 커머스 방송 매니저야\n",
    "        {text}에서 시청자와 소통했던 내용 및 이벤트 진행상황에 대해서만 말해\n",
    "    '''\n",
    "    combine_prompt_template = '''\n",
    "        {text}를 시청하지 못하면 알 수 없을 내용들을 작성해\n",
    "    '''\n",
    "    \n",
    "    MAP_PROMPT = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "    COMBINE_PROMPT = PromptTemplate(template=combine_prompt_template, input_variables=[\"text\"])\n",
    "    \n",
    "    chain = load_summarize_chain(chat_model, chain_type=\"map_reduce\", return_intermediate_steps=True,\n",
    "                                  map_prompt=MAP_PROMPT, combine_prompt=COMBINE_PROMPT)\n",
    "    \n",
    "    return chain({\"input_documents\": docs}, return_only_outputs=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
